{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 4.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: jinja2 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.61.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/examsherpa/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_wen_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0f/dj_hz1316w7c4qhdk33w3p3w0000gn/T/ipykernel_86047/3079700500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0men_core_wen_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'en_core_wen_sm'"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import en_core_web_sm \n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load: insert variable to load pickle into\n",
    "train = pickle.load(open('../extra/pickle/train_bal.pickle', 'rb'))\n",
    "valid = pickle.load(open('../extra/pickle/val_bal.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ICC you should be worried about other things ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@amberhasalamb Can you comment on Ford doing t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@MalcolmNance @montanaisthebes I agree with ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And now for the dish that best represents the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.@mark_kaiserr Im not sexist but every food pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target\n",
       "0  @ICC you should be worried about other things ...       1\n",
       "1  @amberhasalamb Can you comment on Ford doing t...       1\n",
       "2  @MalcolmNance @montanaisthebes I agree with ma...       1\n",
       "3  And now for the dish that best represents the ...       1\n",
       "4  .@mark_kaiserr Im not sexist but every food pl...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ICC you should be worried about other things rather than a sign of patriotism on @msdhoni gloves huh #DhoniKeepsTheGlove #INDvsAUS #ICCWorldCup2019 https://t.co/dPlEcrWHYt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ICC</td>\n",
       "      <td>@ICC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worried</td>\n",
       "      <td>worried</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rather</td>\n",
       "      <td>rather</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>than</td>\n",
       "      <td>than</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sign</td>\n",
       "      <td>sign</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patriotism</td>\n",
       "      <td>patriotism</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@msdhoni</td>\n",
       "      <td>@msdhoni</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gloves</td>\n",
       "      <td>glove</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>huh</td>\n",
       "      <td>huh</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DhoniKeepsTheGlove</td>\n",
       "      <td>dhonikeepstheglove</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INDvsAUS</td>\n",
       "      <td>INDvsAUS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ICCWorldCup2019</td>\n",
       "      <td>iccworldcup2019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://t.co/dPlEcrWHYt</td>\n",
       "      <td>https://t.co/dplecrwhyt</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token                    lemma  stopwords\n",
       "0                      @ICC                     @ICC      False\n",
       "1                       you                      you       True\n",
       "2                    should                   should       True\n",
       "3                        be                       be       True\n",
       "4                   worried                  worried      False\n",
       "5                     about                    about       True\n",
       "6                     other                    other       True\n",
       "7                    things                    thing      False\n",
       "8                    rather                   rather       True\n",
       "9                      than                     than       True\n",
       "10                        a                        a       True\n",
       "11                     sign                     sign      False\n",
       "12                       of                       of       True\n",
       "13               patriotism               patriotism      False\n",
       "14                       on                       on       True\n",
       "15                 @msdhoni                 @msdhoni      False\n",
       "16                   gloves                    glove      False\n",
       "17                      huh                      huh      False\n",
       "18                        #                        #      False\n",
       "19       DhoniKeepsTheGlove       dhonikeepstheglove      False\n",
       "20                        #                        #      False\n",
       "21                 INDvsAUS                 INDvsAUS      False\n",
       "22                        #                        #      False\n",
       "23          ICCWorldCup2019          iccworldcup2019      False\n",
       "24  https://t.co/dPlEcrWHYt  https://t.co/dplecrwhyt      False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s = train.tweet[0]\n",
    "doc = nlp(s)\n",
    "\n",
    "rows = []\n",
    "for token in doc:\n",
    "    rows.append([token, token.lemma_, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['token', 'lemma', 'stopwords'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re_token_match = spacy.tokenizer._get_regex_pattern(nlp.Defaults.token_match)\n",
    "re_token_match = f\"({re_token_match}|#\\\\w+)\"\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ICC</td>\n",
       "      <td>@ICC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worried</td>\n",
       "      <td>worried</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rather</td>\n",
       "      <td>rather</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>than</td>\n",
       "      <td>than</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sign</td>\n",
       "      <td>sign</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>patriotism</td>\n",
       "      <td>patriotism</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@msdhoni</td>\n",
       "      <td>@msdhoni</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gloves</td>\n",
       "      <td>glove</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>huh</td>\n",
       "      <td>huh</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>#DhoniKeepsTheGlove</td>\n",
       "      <td>#dhonikeepstheglove</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#INDvsAUS</td>\n",
       "      <td>#indvsaus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#ICCWorldCup2019</td>\n",
       "      <td>#iccworldcup2019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://t.co/dPlEcrWHYt</td>\n",
       "      <td>https://t.co/dPlEcrWHYt</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      token                    lemma  stopwords\n",
       "0                      @ICC                     @ICC      False\n",
       "1                       you                      you       True\n",
       "2                    should                   should       True\n",
       "3                        be                       be       True\n",
       "4                   worried                  worried      False\n",
       "5                     about                    about       True\n",
       "6                     other                    other       True\n",
       "7                    things                    thing      False\n",
       "8                    rather                   rather       True\n",
       "9                      than                     than       True\n",
       "10                        a                        a       True\n",
       "11                     sign                     sign      False\n",
       "12                       of                       of       True\n",
       "13               patriotism               patriotism      False\n",
       "14                       on                       on       True\n",
       "15                 @msdhoni                 @msdhoni      False\n",
       "16                   gloves                    glove      False\n",
       "17                      huh                      huh      False\n",
       "18      #DhoniKeepsTheGlove      #dhonikeepstheglove      False\n",
       "19                #INDvsAUS                #indvsaus      False\n",
       "20         #ICCWorldCup2019         #iccworldcup2019      False\n",
       "21  https://t.co/dPlEcrWHYt  https://t.co/dPlEcrWHYt      False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(s)\n",
    "\n",
    "rows = []\n",
    "for token in doc:\n",
    "    rows.append([token, token.lemma_, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['token', 'lemma', 'stopwords'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s, nlp, features):\n",
    "    s = s.lower()\n",
    "    doc = nlp(s)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        lemmas.sppend(token.lemma_)\n",
    "    features |= set(lemmas)\n",
    "    freq = {\"#\":0,\"@\":0,\"URL\":0}\n",
    "    for words in lemmas:\n",
    "        freq[str(words)] = 0\n",
    "    for token in doc:\n",
    "        if '#' in str(token): freq['#'] += 1\n",
    "        if \"@\" in str(token): freq['@'] += 1\n",
    "        if \"https://\" in str(token): freq['URL'] += 1\n",
    "        freq[str(token.lemma_)] += 1\n",
    "\n",
    "    return features, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf4417e1580e1af9183bd2ecdc84c6c5be4a00fefee0431cd5dd6903af416b84"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
